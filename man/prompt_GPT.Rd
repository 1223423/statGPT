% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/prompt_GPT.R
\name{prompt_GPT}
\alias{prompt_GPT}
\title{Get OpenAI model completion}
\usage{
prompt_GPT(
  prompt_query,
  prompt_context = "",
  API_KEY = Sys.getenv("OPENAI_API_KEY"),
  MODEL = Sys.getenv("OPENAI_MODEL", "gpt-3.5-turbo"),
  CONTEXT_LIMIT = as.numeric(Sys.getenv("STATGPT_CTXLIM", 2750)),
  TEMPERATURE = as.numeric(Sys.getenv("OPENAI_TEMPERATURE", 0.25))
)
}
\arguments{
\item{prompt_query}{(string) the query to be sent to the AI model.}

\item{prompt_context}{(string) the code context for the query (optional).}

\item{API_KEY}{(string) the OpenAI API key.}

\item{MODEL}{(string) the name of the AI model (optional, default: 'gpt-3.5-turbo').}

\item{CONTEXT_LIMIT}{(integer) the total prompt limit in estimated tokens (optional, default: 2750)}

\item{TEMPERATURE}{(float) the model temperature ranging 0-2 (optional, default: 1)}
}
\value{
(list) of (string) The model completion string
}
\description{
This function takes in a user query and a code context, then prompts the
provided OpenAI model to request a code completion via http request.
}
